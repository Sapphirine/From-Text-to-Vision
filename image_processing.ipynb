{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##image processing script:\n",
    "##1. call our revised YOLO (you only look once) to extract bounding boxes for objects in the iamges\n",
    "##2. split the original image dataset into a set of singal-object images \n",
    "##3. extract the features of using ResNet50\n",
    "##4. cluster the images using k-means\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "#import imageio\n",
    "#imageio.plugins.ffmpeg.download()\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#imagePath = './test_images/test1.jpg'\n",
    "imagePath='data/80.jpg'\n",
    "image = cv2.imread(imagePath)\n",
    "#cv2.imwrite(\"test.png\",image)\n",
    "\n",
    "#image_crop = image[300:650,500:,:]\n",
    "#resized = cv2.resize(image_crop,(448,448))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#function to read the bounding box text file and save it to a list\n",
    "def init():\n",
    "    bbx=open(\"box.txt\",'r')\n",
    "    bbxs=bbx.readlines()\n",
    "    boxes=[]\n",
    "    ori=[]\n",
    "    for line in bbxs:\n",
    "        out.write(line)\n",
    "        w=line.split()\n",
    "        my=[]\n",
    "        for i in range(0,4):\n",
    "            my.append(int(w[i]))\n",
    "            #l r u d\n",
    "        ori.append(my)\n",
    "    bbx.close()\n",
    "    return ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[507, 601, 194, 240], [308, 428, 208, 395], [360, 613, 99, 248], [1, 208, 205, 424]]\n"
     ]
    }
   ],
   "source": [
    "#demo: show the bounding boxes of a given image \n",
    "imagePath='data/80.jpg'\n",
    "image = cv2.imread(imagePath)\n",
    "os.system(\"./darknet detect cfg/yolo.cfg yolo.weights \"+imagePath)\n",
    "my=init()\n",
    "for x in my:\n",
    "    cv2.rectangle(icv, (x[0], x[2]), (x[1], x[3]), (255,0,0), 3))\n",
    "    cv2.imwrite(\"result/example.jpg\",icv)\n",
    "print(my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predict bounding boxes and save the bounding boxes pictures to results/ folder\n",
    "import os\n",
    "files=os.listdir(\"a/\")\n",
    "out=open(\"boxes.txt\",\"w\")\n",
    "for name in files:\n",
    "    imagePath='a/'+name\n",
    "    image = cv2.imread(imagePath)\n",
    "    os.system(\"./darknet detect cfg/yolo.cfg yolo.weights \"+imagePath)\n",
    "    my=init()\n",
    "    resized = cv2.resize(image,(608,608))\n",
    "    icv=resized\n",
    "    i=0\n",
    "    for x in my:\n",
    "        i=i+1\n",
    "        #cv2.rectangle(icv, (x[0], x[2]), (x[1], x[3]), (255,0,0), 3)\n",
    "        cv2.imwrite('results/'+name+'_'+str(i)+\".jpg\",icv[x[2]:x[3],x[0]:x[1]])\n",
    "    out.write(name+'\\t'+str(i)+'\\n')\n",
    "    #cv2.imwrite(\"result/\"+name,icv)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the representation of all bounding box pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.objectives import mean_squared_error, categorical_crossentropy\n",
    "from keras.layers import Input, Convolution2D, Dropout, GlobalAveragePooling2D\n",
    "from keras.layers import Flatten, Dense, GlobalMaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "from scipy.misc import imread, imresize\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#extract features of the bounding box pictures\n",
    "from scipy import misc\n",
    "from keras.preprocessing import image\n",
    "\n",
    "model = ResNet50(weights='imagenet', include_top=False)\n",
    "files=os.listdir('results')\n",
    "#out=open(\"out_id.txt\",'r')\n",
    "img_rep=open(\"img_rep.txt\",'w')\n",
    "#print (len(out))\n",
    "features=[]\n",
    "#text=out.readlines()\n",
    "m=0\n",
    "\n",
    "for id_num in files:\n",
    "    m=m+1\n",
    "    img_path=\"results/\"+id_num\n",
    "\n",
    "    #print(img_path)\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    feature = model.predict(x)\n",
    "    #img_rep.write(str(feature)+'\\n')\n",
    "    features.append(feature[0][0][0])\n",
    "    \n",
    "out.close()\n",
    "img_rep.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# confirm image number\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transfer it to numpyarray\n",
    "f=np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans=KMeans(n_clusters=100,random_state=0).fit(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=kmeans.labels_\n",
    "out=open(\"clusters.txt\",\"w\")\n",
    "i=0\n",
    "for id_num in files:\n",
    "    label=a[i]\n",
    "    sup=id_num.find(\".jpg\")\n",
    "    pic=id_num[:sup]\n",
    "    out.write(pic+\"\\t\"+label+\"\\n\")\n",
    "    i+=1\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py2]",
   "language": "python",
   "name": "conda-env-py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
