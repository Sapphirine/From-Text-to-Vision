{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data augumentation\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img('zjg.jpg')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='preview', save_prefix='photo', save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[  0.           0.           0.         ...,   0.           1.80273604\n",
      "      0.        ]\n",
      "   [  0.           0.           0.         ...,   0.          13.18714333\n",
      "      0.        ]\n",
      "   [  0.           0.           0.         ...,   0.           6.1667676\n",
      "      0.        ]\n",
      "   ..., \n",
      "   [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      "   [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      "   [  0.           0.           0.         ...,   0.           2.44363332\n",
      "      0.        ]]\n",
      "\n",
      "  [[  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      "   [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      "   [  0.           0.           4.36252069 ...,   0.           0.           0.        ]\n",
      "   ..., \n",
      "   [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      "   [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      "   [  0.           0.           0.         ...,   0.           0.           0.        ]]\n",
      "\n",
      "  [[  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      "   [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      "   [  0.           0.           6.71331739 ...,   0.           0.           0.        ]\n",
      "   ..., \n",
      "   [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      "   [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      "   [  0.           0.           0.         ...,   0.           0.           0.        ]]\n",
      "\n",
      "  ..., \n",
      "  [[  3.80261779   0.           7.51615429 ...,   0.           0.           0.        ]\n",
      "   [  9.27715969   0.           0.         ...,   0.           0.           0.        ]\n",
      "   [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      "   ..., \n",
      "   [  0.           0.           0.         ...,   0.           0.\n",
      "      8.02944946]\n",
      "   [  0.           0.           0.         ...,   0.           0.\n",
      "      5.75864029]\n",
      "   [  0.           0.           0.         ...,   0.           0.           0.        ]]\n",
      "\n",
      "  [[  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      "   [  0.           0.           5.18770552 ...,   0.           0.           0.        ]\n",
      "   [  0.           0.          10.02799892 ...,   0.           0.\n",
      "      3.98249078]\n",
      "   ..., \n",
      "   [  0.           0.           0.         ...,   0.           0.\n",
      "      4.93565702]\n",
      "   [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      "   [  0.           0.           0.         ...,   0.           0.96002811\n",
      "      0.        ]]\n",
      "\n",
      "  [[  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      "   [  0.           0.           0.         ...,   0.           0.\n",
      "     26.51954651]\n",
      "   [  0.           0.           0.         ...,   0.           0.\n",
      "     35.57923126]\n",
      "   ..., \n",
      "   [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      "   [  0.           0.           0.         ...,   0.           0.           0.        ]\n",
      "   [  0.           0.          16.25465775 ...,   0.           0.           0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "img_path = 'zjg.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "features = model.predict(x)\n",
    "print (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[  61.64434433    0.           42.45877075 ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.           42.65873337 ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.           22.29956818 ...,    0.            0.\n",
      "       0.        ]\n",
      "   ..., \n",
      "   [   0.            0.            1.70282972 ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]]\n",
      "\n",
      "  [[   0.            0.           42.88956451 ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.           29.51001358\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   ..., \n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]]\n",
      "\n",
      "  [[  41.9142952     0.          291.26016235 ...,    0.           15.72485256\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.           77.85729218\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   ..., \n",
      "   [   0.            0.            0.         ...,    0.            0.94001865\n",
      "       0.        ]\n",
      "   [   0.            0.           49.12719345 ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.          108.98182678 ...,    0.            0.\n",
      "      89.55703735]]\n",
      "\n",
      "  ..., \n",
      "  [[   0.            0.          212.68119812 ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.           10.3278141  ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   ..., \n",
      "   [   0.            0.          166.22155762 ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [ 123.62651062    0.            0.         ...,    0.            0.\n",
      "      85.60778809]]\n",
      "\n",
      "  [[   0.            0.          171.74497986 ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.           54.72651672 ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.          155.81584167 ...,    0.            0.\n",
      "       0.        ]\n",
      "   ..., \n",
      "   [   0.           84.34889984   52.81747055 ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "     108.85983276]]\n",
      "\n",
      "  [[   0.            0.          260.10705566 ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.           23.23109818 ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.            0.         ...,    0.            0.\n",
      "       0.        ]\n",
      "   ..., \n",
      "   [   0.            0.          367.68804932 ...,    0.            0.\n",
      "       0.        ]\n",
      "   [   0.            0.          460.34869385 ...,    0.            0.\n",
      "       0.        ]\n",
      "   [  37.0770607     0.            0.         ...,    0.           26.89677238\n",
      "       0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "base_model = VGG16(weights='imagenet')\n",
    "model = Model(input=base_model.input, output=base_model.get_layer('block4_pool').output)\n",
    "\n",
    "img_path = 'zjg.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "block4_pool_features = model.predict(x)\n",
    "print (block4_pool_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune ResNet50 on a new set of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fit_generator() missing 2 required positional arguments: 'samples_per_epoch' and 'nb_epoch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d768ca63f144>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[1;31m# train the model on the new data for a few epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[1;31m# at this point, the top layers are well trained and we can start fine-tuning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit_generator() missing 2 required positional arguments: 'samples_per_epoch' and 'nb_epoch'"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(200, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(input=base_model.input, output=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "model.fit_generator(...)\n",
    "\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 172 layers and unfreeze the rest:\n",
    "for layer in model.layers[:172]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[172:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "model.fit_generator(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
